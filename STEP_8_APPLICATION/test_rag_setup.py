"""
Test RAG Chatbot Setup
Quick verification script
"""

import sys
import os

print("üîç Testing RAG Chatbot Setup...\n")

# Test 1: Check Python version
print("1Ô∏è‚É£ Python Version:")
print(f"   {sys.version}")
if sys.version_info < (3, 10):
    print("   ‚ö†Ô∏è  Python 3.10+ recommended")
else:
    print("   ‚úÖ Python version OK\n")

# Test 2: Check .env file
print("2Ô∏è‚É£ Environment Variables:")
try:
    from dotenv import load_dotenv
    load_dotenv()
    
    groq_key = os.getenv("GROQ_API_TOKEN")
    if groq_key:
        print(f"   ‚úÖ GROQ_API_TOKEN found (length: {len(groq_key)})")
    else:
        print("   ‚ùå GROQ_API_TOKEN not found in .env")
    print()
except ImportError:
    print("   ‚ùå python-dotenv not installed")
    print("   Install: pip install python-dotenv\n")

# Test 3: Check required packages
print("3Ô∏è‚É£ Required Packages:")
required_packages = [
    "langchain",
    "langchain_groq",
    "langchain_chroma",
    "langchain_community",
    "pypdf",
    "chromadb",
    "dotenv"
]

for package in required_packages:
    try:
        __import__(package)
        print(f"   ‚úÖ {package}")
    except ImportError:
        print(f"   ‚ùå {package} - Not installed")

print()

# Test 4: Check Ollama
print("4Ô∏è‚É£ Embeddings (Local - Sentence Transformers):")
try:
    from langchain_community.embeddings import HuggingFaceEmbeddings
    model_name = "sentence-transformers/all-MiniLM-L6-v2"
    embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={"device": "cpu"})
    # Try to create a test embedding
    test_result = embeddings.embed_query("test")
    if test_result and isinstance(test_result, list) and len(test_result) > 0:
        print("   ‚úÖ HuggingFace embeddings working")
        print(f"   ‚úÖ Model: {model_name}")
    else:
        print("   ‚ö†Ô∏è  Embedding vector is empty")
except Exception as e:
    print(f"   ‚ùå Embeddings failed: {str(e)}")
    print("   Reinstall: pip install sentence-transformers langchain-community")

print()

# Test 5: Check Groq API
print("5Ô∏è‚É£ Groq API Connection:")
try:
    from langchain_groq import ChatGroq
    groq_key = os.getenv("GROQ_API_TOKEN")
    if groq_key:
        llm = ChatGroq(
            groq_api_key=groq_key,
            model_name="llama-3.1-8b-instant",  # Updated to new supported model
            temperature=0.7
        )
        print("   ‚úÖ Groq LLM initialized")
        
        # Try a simple query
        try:
            response = llm.invoke("Say 'Hello'")
            print("   ‚úÖ Groq API connection successful")
            print(f"   Response: {response.content}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Groq API call failed: {str(e)}")
    else:
        print("   ‚ùå GROQ_API_TOKEN not found")
except Exception as e:
    print(f"   ‚ùå Groq setup failed: {str(e)}")

print("\n" + "="*50)
print("‚ú® Setup Check Complete!")
print("="*50)
